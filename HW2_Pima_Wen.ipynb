{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Supervised Learning\n",
    "\n",
    "\n",
    "# Dataset: [Pima Indians Diabetes Dataset](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "# [Data Description:](https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.names)\n",
    "\n",
    "\n",
    "# Due: 2/8 (beginning of class)\n",
    "\n",
    "\n",
    "# Format: ipython notebook submission on GitHub\n",
    "\n",
    "- send link to your repository to Mason and Lema\n",
    "\n",
    "\n",
    "## Instructions: answer the following questions with data and visuals\n",
    "\n",
    "- Describe the content of the dataset and its goals\n",
    "- Describe the features and formulate a hypothesis on which might be relevant in predicting diabetes\n",
    "- Describe the missing/NULL values. Decide if you should impute or drop them and justify your choice.\n",
    "- Come up with a benchmark for the minimum performance that an algorithm should have on this dataset\n",
    "- What's the best performance you can get with kNN? Is kNN a good choice for this dataset?\n",
    "- What's the best performance you can get with Naive Bayes? Is NB a good choice for this dataset?\n",
    "- What's the best performance you can get with Logistic Regression? Is LR a good choice for this dataset?\n",
    "- What's the best performance you can get with Random Forest? Is RF a good choice for this dataset?\n",
    "- If you could only choose one, which classifer from the above that you already ran is best? How do you define best? (hint: could be prediction accuracy, running time, interpretability, etc)\n",
    "\n",
    "\n",
    "## Note: you should know by now, but here is the order of importance:\n",
    "\n",
    "- Your analysis (there is no \"right\" answer, only good and bad defense of it)\n",
    "- Your visuals\n",
    "- Your coding implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "raw_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data',\\\n",
    "                    sep=',',header=None,\\\n",
    "                    names=['preg','glc_concen','blood_pres','skin','insulin','mass','pedigree','age','class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>glc_concen</th>\n",
       "      <th>blood_pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  glc_concen  blood_pres  skin  insulin  mass  pedigree  age  class\n",
       "0     6         148          72    35        0  33.6     0.627   50      1\n",
       "1     1          85          66    29        0  26.6     0.351   31      0\n",
       "2     8         183          64     0        0  23.3     0.672   32      1\n",
       "3     1          89          66    23       94  28.1     0.167   21      0\n",
       "4     0         137          40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a peak at the data structure\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "preg          768 non-null int64\n",
      "glc_concen    768 non-null int64\n",
      "blood_pres    768 non-null int64\n",
      "skin          768 non-null int64\n",
      "insulin       768 non-null int64\n",
      "mass          768 non-null float64\n",
      "pedigree      768 non-null float64\n",
      "age           768 non-null int64\n",
      "class         768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 60.0 KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preg          False\n",
       "glc_concen    False\n",
       "blood_pres    False\n",
       "skin          False\n",
       "insulin       False\n",
       "mass          False\n",
       "pedigree      False\n",
       "age           False\n",
       "class         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>glc_concen</th>\n",
       "      <th>blood_pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg  glc_concen  blood_pres        skin     insulin        mass  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the content of the dataset and its goals**\n",
    "==============\n",
    "- The dataset has 768 observations and 9 variables.  \n",
    "- All variables are of numerical values, among which two are composed of floating numbers and the rest are integers.\n",
    "- The 'class' variable contains binary values, which is something the model ultimately tries to test and predict. \n",
    "- Since the 'class' variable are binary values, its mean equals to the percentage of people who have diabetes in \n",
    "  this sample dataset. It is not presesentive to the general Pima Indian population since the given observations are on\n",
    "  21+ years old females only. \n",
    "- The dataset contains no missing values per se. However, if we look at the minimum value of each variable summarized in the       above table, the zero values present in 'blood_pres', 'skin','insulin','mass','pedigree' are likely to be the 'missing           values' that we were talking about. Since measurements for those indicators should be above-zero numbers by common sense.\n",
    "-----------------\n",
    "\n",
    "The **goal** would be to explore and determine what the best machine learning algorithm to use to predict on the diabetes rate among \n",
    "21+ years' old Pima Indian women based on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the features and formulate a hypothesis on which might be relevant in predicting diabetes**\n",
    "\n",
    "**Describe the missing/NULL values. Decide if you should impute or drop them and justify your choice.**\n",
    "==============\n",
    "- The last column 'class' is the result we tend to predict. So we have 8 features.\n",
    "- Based on my medical knowledge, 'plasma glucose concentration', '2-Hour serum insulin','Diabetes pedigree function' seem to \n",
    "   have high correlations with 'getting diabetes', while 'Diastolic blood pressure','Triceps skin fold thickness' and 'Age' \n",
    "   might have some influence on the diagnosis. \n",
    "- To understand which features are relevant and how much they contribute to the diabetes prediction, we could run a variable \n",
    "   correlation matrix. \n",
    "- The zeros values in certain features need to be manupulated before running correlation matrix. We could either \n",
    "       (1) drop the zeros\n",
    "       (2) replace the zeros with some values (e.g.mean)\n",
    "- The maximum value in 'insulin' column is significantly higher than mean (846 vs 80), which may indicate it as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0.0065% missing data in variable 'glc_concen'. \n",
      "There are 0.0456% missing data in variable 'blood_pres'. \n",
      "There are 0.2956% missing data in variable 'skin'. \n",
      "There are 0.4870% missing data in variable 'insulin'. \n",
      "There are 0.0143% missing data in variable 'mass'. \n"
     ]
    }
   ],
   "source": [
    "print \"There are %.4f%% missing data in variable 'glc_concen'. \" %(1-float(np.count_nonzero(raw_data['glc_concen']))/768)\n",
    "print \"There are %.4f%% missing data in variable 'blood_pres'. \" %(1-float(np.count_nonzero(raw_data['blood_pres']))/768)\n",
    "print \"There are %.4f%% missing data in variable 'skin'. \" %(1-float(np.count_nonzero(raw_data['skin']))/768)\n",
    "print \"There are %.4f%% missing data in variable 'insulin'. \" %(1-float(np.count_nonzero(raw_data['insulin']))/768)\n",
    "print \"There are %.4f%% missing data in variable 'mass'. \" %(1-float(np.count_nonzero(raw_data['mass']))/768)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the percentage of missing data, aka, zero values is very small, we could drop them.\n",
    "\n",
    "But we need to first replace all zero values with NaN before dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[846,\n",
       " 744,\n",
       " 680,\n",
       " 600,\n",
       " 579,\n",
       " 545,\n",
       " 543,\n",
       " 540,\n",
       " 510,\n",
       " 495,\n",
       " 495,\n",
       " 485,\n",
       " 480,\n",
       " 480,\n",
       " 478,\n",
       " 474,\n",
       " 465,\n",
       " 440,\n",
       " 415,\n",
       " 402,\n",
       " 392,\n",
       " 387,\n",
       " 375,\n",
       " 370,\n",
       " 360,\n",
       " 342,\n",
       " 335,\n",
       " 330,\n",
       " 328,\n",
       " 326,\n",
       " 325,\n",
       " 325,\n",
       " 325,\n",
       " 321,\n",
       " 318,\n",
       " 310,\n",
       " 304,\n",
       " 300,\n",
       " 293,\n",
       " 293,\n",
       " 291,\n",
       " 285,\n",
       " 285,\n",
       " 284,\n",
       " 280,\n",
       " 278,\n",
       " 277,\n",
       " 275,\n",
       " 274,\n",
       " 272,\n",
       " 271,\n",
       " 270,\n",
       " 265,\n",
       " 265,\n",
       " 258,\n",
       " 255,\n",
       " 250,\n",
       " 249,\n",
       " 245,\n",
       " 240,\n",
       " 240,\n",
       " 237,\n",
       " 235,\n",
       " 231,\n",
       " 231,\n",
       " 230,\n",
       " 230,\n",
       " 228,\n",
       " 225,\n",
       " 225,\n",
       " 220,\n",
       " 220,\n",
       " 215,\n",
       " 215,\n",
       " 215,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 207,\n",
       " 207,\n",
       " 205,\n",
       " 205,\n",
       " 204,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 196,\n",
       " 194,\n",
       " 194,\n",
       " 194,\n",
       " 193,\n",
       " 192,\n",
       " 192,\n",
       " 191,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 188,\n",
       " 185,\n",
       " 185,\n",
       " 184,\n",
       " 183,\n",
       " 182,\n",
       " 182,\n",
       " 182,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 178,\n",
       " 176,\n",
       " 176,\n",
       " 176,\n",
       " 175,\n",
       " 175,\n",
       " 175,\n",
       " 171,\n",
       " 170,\n",
       " 170,\n",
       " 168,\n",
       " 168,\n",
       " 168,\n",
       " 168,\n",
       " 167,\n",
       " 167,\n",
       " 166,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 159,\n",
       " 158,\n",
       " 158,\n",
       " 156,\n",
       " 156,\n",
       " 156,\n",
       " 155,\n",
       " 155,\n",
       " 155,\n",
       " 155,\n",
       " 152,\n",
       " 152,\n",
       " 150,\n",
       " 150,\n",
       " 148,\n",
       " 148,\n",
       " 146,\n",
       " 145,\n",
       " 145,\n",
       " 145,\n",
       " 144,\n",
       " 144,\n",
       " 142,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 132,\n",
       " 132,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 129,\n",
       " 128,\n",
       " 127,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 122,\n",
       " 122,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 119,\n",
       " 116,\n",
       " 116,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 114,\n",
       " 114,\n",
       " 112,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 108,\n",
       " 106,\n",
       " 106,\n",
       " 106,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 99,\n",
       " 99,\n",
       " 96,\n",
       " 96,\n",
       " 95,\n",
       " 95,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 85,\n",
       " 84,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 82,\n",
       " 82,\n",
       " 82,\n",
       " 81,\n",
       " 79,\n",
       " 79,\n",
       " 78,\n",
       " 78,\n",
       " 77,\n",
       " 77,\n",
       " 76,\n",
       " 76,\n",
       " 76,\n",
       " 76,\n",
       " 76,\n",
       " 75,\n",
       " 75,\n",
       " 75,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 73,\n",
       " 72,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 68,\n",
       " 67,\n",
       " 67,\n",
       " 66,\n",
       " 66,\n",
       " 66,\n",
       " 66,\n",
       " 66,\n",
       " 65,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 61,\n",
       " 60,\n",
       " 60,\n",
       " 59,\n",
       " 58,\n",
       " 58,\n",
       " 57,\n",
       " 57,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 55,\n",
       " 55,\n",
       " 54,\n",
       " 54,\n",
       " 54,\n",
       " 54,\n",
       " 53,\n",
       " 53,\n",
       " 52,\n",
       " 51,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 46,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 40,\n",
       " 38,\n",
       " 37,\n",
       " 37,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 32,\n",
       " 29,\n",
       " 25,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 18,\n",
       " 18,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a closer look at column 'insulin' to determine if it is necessary to drop 'outliers'. \n",
    "\n",
    "sorted(raw_data['insulin'],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are numbers like 744, 680, 600, 846 doesn't seems to be that of an anomaly. So we can just keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>glc_concen</th>\n",
       "      <th>blood_pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  glc_concen  blood_pres  skin  insulin  mass  pedigree  age  class\n",
       "0     6         148          72    35      NaN  33.6     0.627   50      1\n",
       "1     1          85          66    29      NaN  26.6     0.351   31      0\n",
       "2     8         183          64   NaN      NaN  23.3     0.672   32      1\n",
       "3     1          89          66    23       94  28.1     0.167   21      0\n",
       "4     0         137          40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data.copy().replace({'glc_concen':{0:np.nan},'blood_pres':{0:np.nan},'blood_pres':{0:np.nan},'skin':{0:np.nan},'insulin':{0:np.nan},\\\n",
    "                    'mass':{0:np.nan}})\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.copy() \n",
    "\n",
    "df.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the sample size has been reduced to 392 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>glc_concen</th>\n",
       "      <th>blood_pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.301020</td>\n",
       "      <td>122.627551</td>\n",
       "      <td>70.663265</td>\n",
       "      <td>29.145408</td>\n",
       "      <td>156.056122</td>\n",
       "      <td>33.086224</td>\n",
       "      <td>0.523046</td>\n",
       "      <td>30.864796</td>\n",
       "      <td>0.331633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.211424</td>\n",
       "      <td>30.860781</td>\n",
       "      <td>12.496092</td>\n",
       "      <td>10.516424</td>\n",
       "      <td>118.841690</td>\n",
       "      <td>7.027659</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>10.200777</td>\n",
       "      <td>0.471401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg  glc_concen  blood_pres        skin     insulin        mass  \\\n",
       "count  392.000000  392.000000  392.000000  392.000000  392.000000  392.000000   \n",
       "mean     3.301020  122.627551   70.663265   29.145408  156.056122   33.086224   \n",
       "std      3.211424   30.860781   12.496092   10.516424  118.841690    7.027659   \n",
       "min      0.000000   56.000000   24.000000    7.000000   14.000000   18.200000   \n",
       "25%      1.000000   99.000000   62.000000   21.000000   76.750000   28.400000   \n",
       "50%      2.000000  119.000000   70.000000   29.000000  125.500000   33.200000   \n",
       "75%      5.000000  143.000000   78.000000   37.000000  190.000000   37.100000   \n",
       "max     17.000000  198.000000  110.000000   63.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age       class  \n",
       "count  392.000000  392.000000  392.000000  \n",
       "mean     0.523046   30.864796    0.331633  \n",
       "std      0.345488   10.200777    0.471401  \n",
       "min      0.085000   21.000000    0.000000  \n",
       "25%      0.269750   23.000000    0.000000  \n",
       "50%      0.449500   27.000000    0.000000  \n",
       "75%      0.687000   36.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>glc_concen</th>\n",
       "      <th>blood_pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>preg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198291</td>\n",
       "      <td>0.213355</td>\n",
       "      <td>0.093209</td>\n",
       "      <td>0.078984</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.679608</td>\n",
       "      <td>0.256566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glc_concen</th>\n",
       "      <td>0.198291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210027</td>\n",
       "      <td>0.198856</td>\n",
       "      <td>0.581223</td>\n",
       "      <td>0.209516</td>\n",
       "      <td>0.140180</td>\n",
       "      <td>0.343641</td>\n",
       "      <td>0.515703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_pres</th>\n",
       "      <td>0.213355</td>\n",
       "      <td>0.210027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232571</td>\n",
       "      <td>0.098512</td>\n",
       "      <td>0.304403</td>\n",
       "      <td>-0.015971</td>\n",
       "      <td>0.300039</td>\n",
       "      <td>0.192673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>0.093209</td>\n",
       "      <td>0.198856</td>\n",
       "      <td>0.232571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182199</td>\n",
       "      <td>0.664355</td>\n",
       "      <td>0.160499</td>\n",
       "      <td>0.167761</td>\n",
       "      <td>0.255936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>0.078984</td>\n",
       "      <td>0.581223</td>\n",
       "      <td>0.098512</td>\n",
       "      <td>0.182199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.226397</td>\n",
       "      <td>0.135906</td>\n",
       "      <td>0.217082</td>\n",
       "      <td>0.301429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>-0.025347</td>\n",
       "      <td>0.209516</td>\n",
       "      <td>0.304403</td>\n",
       "      <td>0.664355</td>\n",
       "      <td>0.226397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.158771</td>\n",
       "      <td>0.069814</td>\n",
       "      <td>0.270118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigree</th>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.140180</td>\n",
       "      <td>-0.015971</td>\n",
       "      <td>0.160499</td>\n",
       "      <td>0.135906</td>\n",
       "      <td>0.158771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085029</td>\n",
       "      <td>0.209330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.679608</td>\n",
       "      <td>0.343641</td>\n",
       "      <td>0.300039</td>\n",
       "      <td>0.167761</td>\n",
       "      <td>0.217082</td>\n",
       "      <td>0.069814</td>\n",
       "      <td>0.085029</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0.256566</td>\n",
       "      <td>0.515703</td>\n",
       "      <td>0.192673</td>\n",
       "      <td>0.255936</td>\n",
       "      <td>0.301429</td>\n",
       "      <td>0.270118</td>\n",
       "      <td>0.209330</td>\n",
       "      <td>0.350804</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                preg  glc_concen  blood_pres      skin   insulin      mass  \\\n",
       "preg        1.000000    0.198291    0.213355  0.093209  0.078984 -0.025347   \n",
       "glc_concen  0.198291    1.000000    0.210027  0.198856  0.581223  0.209516   \n",
       "blood_pres  0.213355    0.210027    1.000000  0.232571  0.098512  0.304403   \n",
       "skin        0.093209    0.198856    0.232571  1.000000  0.182199  0.664355   \n",
       "insulin     0.078984    0.581223    0.098512  0.182199  1.000000  0.226397   \n",
       "mass       -0.025347    0.209516    0.304403  0.664355  0.226397  1.000000   \n",
       "pedigree    0.007562    0.140180   -0.015971  0.160499  0.135906  0.158771   \n",
       "age         0.679608    0.343641    0.300039  0.167761  0.217082  0.069814   \n",
       "class       0.256566    0.515703    0.192673  0.255936  0.301429  0.270118   \n",
       "\n",
       "            pedigree       age     class  \n",
       "preg        0.007562  0.679608  0.256566  \n",
       "glc_concen  0.140180  0.343641  0.515703  \n",
       "blood_pres -0.015971  0.300039  0.192673  \n",
       "skin        0.160499  0.167761  0.255936  \n",
       "insulin     0.135906  0.217082  0.301429  \n",
       "mass        0.158771  0.069814  0.270118  \n",
       "pedigree    1.000000  0.085029  0.209330  \n",
       "age         0.085029  1.000000  0.350804  \n",
       "class       0.209330  0.350804  1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run a feature correlation matrix\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the matrix table, there are preg-age, glc_concen-insulin, skin-mass these three pairs that have strong correlations. \n",
    "This will be reference for later algorithm choosing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Come up with a benchmark for the minimum performance that an algorithm should have on this dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create s 'dummy' models. The DummyClassifier will be a baseline to compare with other classifiers.\n",
    "\n",
    "DummyRegressor predicts mean; DummyClassifier predicts the most common class. We'll try to beat them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "\n",
    "dc = DummyClassifier()\n",
    "dr = DummyRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data split\n",
    "\n",
    "pima_labels = df['class']\n",
    "pima_X = df.drop('class', axis=1)\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pima_X, pima_labels, \n",
    "                                                    test_size=0.2, random_state=7)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the best performance you can get with kNN? Is kNN a good choice for this dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10 cross validation iterations with 20% test / 80% train\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "cv = ShuffleSplit(X_train.shape[0], n_iter=10, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardization: bring all of the features onto the same scale\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "# transform our training features\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "# transform the testing features in the same way\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>glc_concen</th>\n",
       "      <th>blood_pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.802410</td>\n",
       "      <td>-0.544995</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>0.294995</td>\n",
       "      <td>-0.733566</td>\n",
       "      <td>-0.304580</td>\n",
       "      <td>-1.113849</td>\n",
       "      <td>0.609127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.492726</td>\n",
       "      <td>-0.741142</td>\n",
       "      <td>-1.281977</td>\n",
       "      <td>-0.081876</td>\n",
       "      <td>-0.603972</td>\n",
       "      <td>0.142798</td>\n",
       "      <td>-0.075459</td>\n",
       "      <td>-0.092185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.055699</td>\n",
       "      <td>0.141523</td>\n",
       "      <td>1.095149</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.536456</td>\n",
       "      <td>-0.318560</td>\n",
       "      <td>-0.017617</td>\n",
       "      <td>-0.693310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.126644</td>\n",
       "      <td>-0.185390</td>\n",
       "      <td>0.302773</td>\n",
       "      <td>-1.306709</td>\n",
       "      <td>-0.413901</td>\n",
       "      <td>-0.933706</td>\n",
       "      <td>-1.155164</td>\n",
       "      <td>-0.693310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.436329</td>\n",
       "      <td>-0.316155</td>\n",
       "      <td>-0.172652</td>\n",
       "      <td>-0.647183</td>\n",
       "      <td>-0.508936</td>\n",
       "      <td>0.156779</td>\n",
       "      <td>-0.582259</td>\n",
       "      <td>-0.492935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       preg  glc_concen  blood_pres      skin   insulin      mass  pedigree  \\\n",
       "0  0.802410   -0.544995   -0.014177  0.294995 -0.733566 -0.304580 -1.113849   \n",
       "1  0.492726   -0.741142   -1.281977 -0.081876 -0.603972  0.142798 -0.075459   \n",
       "2 -1.055699    0.141523    1.095149  0.012342  0.536456 -0.318560 -0.017617   \n",
       "3 -0.126644   -0.185390    0.302773 -1.306709 -0.413901 -0.933706 -1.155164   \n",
       "4 -0.436329   -0.316155   -0.172652 -0.647183 -0.508936  0.156779 -0.582259   \n",
       "\n",
       "        age  \n",
       "0  0.609127  \n",
       "1 -0.092185  \n",
       "2 -0.693310  \n",
       "3 -0.693310  \n",
       "4 -0.492935  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now all features are on the same scale\n",
    "\n",
    "pd.DataFrame(X_train_std, columns=X_train.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
